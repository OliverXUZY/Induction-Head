vocab_size: 5
max_seq_len: 60
sample_size: 2000
sample_size_test: 500
num_epoch: 500
batch_size: 50
num_heads: 1
fancy_opt: False
use_wd: True
lr: 0.001
wd: 5e-4
wd_2: 0
num_layers: 2

add_embed: True
train_from_scratch: False
residual: True
dropout: 0.1
norm: True
outdim_truncate: False
trainable: [True, True]


# save_epoch: 50
ckpt_path: ./save/layer2

